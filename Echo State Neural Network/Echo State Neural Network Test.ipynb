{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a636ad86",
   "metadata": {},
   "source": [
    "# How to Echo State\n",
    "## By Kevin G. R. Pergher\n",
    "Um passo a passo de como gerar e aplicar redes ESN em séries temporais\n",
    "\n",
    "### (0) Import das bibliotecas a serem utilizadas & funções úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed015cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13cc0f",
   "metadata": {},
   "source": [
    "Funções auxiliares a serem utilizadas durante o processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9861e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garante o formato das colunas para arrays unidimensionais\n",
    "def reshape(df):\n",
    "    if len(df.shape) < 2:\n",
    "        return numpy.reshape(df, (df.shape[0], 1))\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416ccc1",
   "metadata": {},
   "source": [
    "### (I) Extração e tratamento dos dados\n",
    "\n",
    "Nesse momento, carregamos o **dataset** de interesse (série temporal). Por conta da biblioteca Numpy é necessário garantir com a função **reshape()** o formato do array (há ausência de valor de colunas quando a série é unidimensional).\n",
    "\n",
    "Em nossa aplicações, **K** é o número de colunas/variáveis de input a serem utilizadas (i.e. $X_0$, $X_1$, ..., $X_{K-1}$). Como em nossa aplicações utilizamos a série para prever \"ela mesma no futuro\", o número de colunas/variáveis de output **L** equivale ao de input.\n",
    "\n",
    "### CORREÇÃO\n",
    "**K** não é, nem precisa ser, igual ou equivalente a **L**.\n",
    "**K** é o sinal de entrada, portanto **K** é a tua janela de entrada. Na verdade, em todos os casos que vamos utilizar a ESN, **K** é muito diferente de **L**. Vamos lá: no caso da Mackey-Glass, **K** é a janela de entrada (maior que 1) e **L** é o valor alvo, é igual a 1. Precisa resolver isso daqui o quanto antes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3ed04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.50345012, -0.50072158],\n",
       "       [ 1.1035704 , -0.50072158],\n",
       "       [-0.97664434,  1.10224828],\n",
       "       ...,\n",
       "       [ 1.57941742, -0.36847491],\n",
       "       [-1.68841231,  1.59306695],\n",
       "       [-1.0234445 , -1.6818749 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = reshape(numpy.loadtxt('NormHenon.txt', delimiter = \",\"))\n",
    "\n",
    "K = dataset.shape[1]\n",
    "L = K\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85094f00",
   "metadata": {},
   "source": [
    "Definimos algumas variáveis relativas ao processamento a seguir, **steps** é o número de passos adiante que pretendemos prever (steps ahead), **train_length** é o tamanho (número de observações) da janela de treino e **test_length** é o tamanho (número de observações) da janela de teste/validação.\n",
    "\n",
    "A variável **transiente** equivale aos dados descartados do período de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c11ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1\n",
    "\n",
    "train_length = 3000\n",
    "test_length = 1000\n",
    "\n",
    "transiente = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2030569",
   "metadata": {},
   "source": [
    "Definimos **train_dataset** como a janela de treino e **test_dataset** como a janela de teste. Definimos **train_target** como a janela de treino deslocada $n$ steps à frente para fins de aplicação da regressão de Ridge e **test_dataset** como a janela de teste deslocada $n$ steps à frente para fins de medida de erro do modelo. As janelas de teste se iniciam após as janelas de treino (incluindo o target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd51a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[0 : train_length, :]\n",
    "train_target = dataset[None, steps + transiente : train_length + steps, :]\n",
    "\n",
    "test_dataset = dataset[train_length : train_length + test_length, :]\n",
    "test_target = dataset[None, train_length + steps : train_length + test_length + steps, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd991933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho - Treino:  (3000, 2)\n",
      "Tamanho - Target/Treino:  (1, 2500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho - Treino: \", train_dataset.shape)\n",
    "print(\"Tamanho - Target/Treino: \", train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b182c9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50345012, -0.50072158],\n",
       "       [ 1.1035704 , -0.50072158],\n",
       "       [-0.97664434,  1.10224828],\n",
       "       ...,\n",
       "       [ 1.53127093, -0.78401452],\n",
       "       [-1.70194019,  1.54293806],\n",
       "       [-1.08426284, -1.69490931]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11309db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.54293852,  0.30451498],\n",
       "        [ 0.22823854,  0.53618457],\n",
       "        [ 0.83778263,  0.22314368],\n",
       "        ...,\n",
       "        [-1.70194019,  1.54293806],\n",
       "        [-1.08426284, -1.69490931],\n",
       "        [-0.08058896, -1.08515286]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f145b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho - Teste:  (1000, 2)\n",
      "Tamanho - Target/Teste:  (1, 1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho - Teste: \", test_dataset.shape)\n",
    "print(\"Tamanho - Target/Teste: \", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45d296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08058896, -1.08515286],\n",
       "       [ 0.59978986, -0.0820576 ],\n",
       "       [ 0.00855218,  0.59305357],\n",
       "       ...,\n",
       "       [ 0.86624938,  0.12923607],\n",
       "       [-0.41309421,  0.86113568],\n",
       "       [ 1.6000105 , -0.41079576]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1deb95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.59978986, -0.0820576 ],\n",
       "        [ 0.00855218,  0.59305357],\n",
       "        [ 1.16839323,  0.00592743],\n",
       "        ...,\n",
       "        [-0.41309421,  0.86113568],\n",
       "        [ 1.6000105 , -0.41079576],\n",
       "        [-1.72740329,  1.61454086]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffee02",
   "metadata": {},
   "source": [
    "### (II) Criação do reservatório\n",
    "\n",
    "Definimos o número de neurônios na camada oculta do reservatório, chamado **N (neurons)**, e a taxa de vazamento espectral **leaking_rate** (entre 0 e 1). \n",
    "\n",
    "O **input_scaling** define a escala dos valores da matriz de pesos de entrada e **spectral_radius** define o raio espectral desejado para a matriz de pesos do reservatório.\n",
    "\n",
    "Define-se a semente do gerador para reprodução do experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20e5e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "leaking_rate = 0.3\n",
    "input_scaling = 1\n",
    "spectral_radius = 1.25\n",
    "\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6099ec0",
   "metadata": {},
   "source": [
    "São criadas duas matrizes aleatórias, através de uma distribuição uniforme de valores entre $-0,5$ e $0,5$. A matriz **W_input** equivale aos pesos de conexão entre a entrada (input) e o reservoir e têm dimensões $N\\ x\\ (K\\ +\\ 1)$ pois considera o input e o bias, a matriz é escalada por **input_scaling**. \n",
    "\n",
    "A matriz **W_reservoir** é definida como a matriz de pesos do reservatório (inter e intra neurônios) e têm dimensão $N\\ x\\ N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54a768c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_input = (numpy.random.rand(N, 1 + K) - 0.5) * input_scaling\n",
    "W_reservoir = numpy.random.rand(N, N) - 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed838ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12545988,  0.45071431,  0.23199394],\n",
       "       [ 0.09865848, -0.34398136, -0.34400548],\n",
       "       [-0.44191639,  0.36617615,  0.10111501],\n",
       "       [ 0.20807258, -0.47941551,  0.46990985],\n",
       "       [ 0.33244264, -0.28766089, -0.31817503],\n",
       "       [-0.31659549, -0.19575776,  0.02475643],\n",
       "       [-0.06805498, -0.20877086,  0.11185289],\n",
       "       [-0.36050614, -0.20785535, -0.13363816],\n",
       "       [-0.04393002,  0.28517596, -0.30032622],\n",
       "       [ 0.01423444,  0.09241457, -0.45354959],\n",
       "       [ 0.10754485, -0.32947588, -0.43494841],\n",
       "       [ 0.44888554,  0.46563203,  0.30839735],\n",
       "       [-0.19538623, -0.40232789,  0.18423303],\n",
       "       [-0.05984751, -0.37796177, -0.00482309],\n",
       "       [-0.46561148,  0.4093204 , -0.24122002],\n",
       "       [ 0.16252228, -0.18828892,  0.02006802],\n",
       "       [ 0.04671028, -0.31514554,  0.46958463],\n",
       "       [ 0.27513282,  0.43949894,  0.39482735],\n",
       "       [ 0.09789998,  0.42187424, -0.4115075 ],\n",
       "       [-0.30401714, -0.45477271, -0.17466967],\n",
       "       [-0.11132271, -0.22865097,  0.32873751],\n",
       "       [-0.14324667, -0.21906549,  0.04269608],\n",
       "       [-0.35907578,  0.30219698, -0.42544936],\n",
       "       [ 0.48688694,  0.27224477, -0.30128432],\n",
       "       [-0.49447788,  0.31546143,  0.20685734],\n",
       "       [ 0.22900717,  0.27127035, -0.42595535],\n",
       "       [-0.14153427, -0.38413094,  0.36310343],\n",
       "       [ 0.12329813, -0.16910198, -0.43644165],\n",
       "       [-0.18901768, -0.17481668,  0.22960618],\n",
       "       [ 0.13755747,  0.38721274, -0.02778507],\n",
       "       [-0.38040575,  0.21324479,  0.26078505],\n",
       "       [ 0.0612772 ,  0.27096718, -0.0062044 ],\n",
       "       [ 0.02273283, -0.07245898, -0.47458087],\n",
       "       [-0.39210857, -0.46857081,  0.13641041],\n",
       "       [-0.18564402,  0.00857069,  0.40756647],\n",
       "       [-0.25070777, -0.08961708,  0.25555114],\n",
       "       [-0.27120183, -0.42302009, -0.21024855],\n",
       "       [-0.33877871,  0.42969765,  0.30812038],\n",
       "       [ 0.13340376,  0.37146059,  0.30367208],\n",
       "       [-0.31342994,  0.392559  ,  0.03934224],\n",
       "       [ 0.30744016,  0.3960913 , -0.18199653],\n",
       "       [-0.38994808, -0.27206484, -0.07289221],\n",
       "       [ 0.31801477,  0.36073058, -0.49304787],\n",
       "       [ 0.0107473 , -0.082589  , -0.27789219],\n",
       "       [-0.38013463, -0.16238483,  0.4429097 ],\n",
       "       [-0.17679707,  0.01879062,  0.20301896],\n",
       "       [-0.1363704 ,  0.47178208,  0.46244729],\n",
       "       [-0.2482177 , -0.00275149, -0.19912169],\n",
       "       [-0.21515951, -0.46311305,  0.10956433],\n",
       "       [ 0.00267902, -0.44852125, -0.22135354]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9d773e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.08265886e-01, -2.60438109e-01, -3.55105128e-01, ...,\n",
       "         3.97110260e-01,  3.87086424e-01,  2.79875546e-01],\n",
       "       [ 1.42031646e-01, -4.15860035e-01, -3.38371286e-01, ...,\n",
       "         4.66654819e-01,  4.63619977e-01,  3.53009455e-01],\n",
       "       [-2.05551108e-01, -1.14902271e-01,  3.51136672e-01, ...,\n",
       "        -2.84178973e-01,  1.22890476e-01, -4.14652535e-01],\n",
       "       ...,\n",
       "       [ 3.27518922e-01,  2.64527795e-01,  7.35289515e-02, ...,\n",
       "        -9.24569690e-02, -9.28935109e-02, -4.33990156e-01],\n",
       "       [-1.51179466e-01, -3.89001901e-01,  3.08235210e-01, ...,\n",
       "        -3.30457718e-03, -2.15725907e-01, -3.66171637e-01],\n",
       "       [ 1.29557697e-01, -4.45667965e-01,  2.48645234e-01, ...,\n",
       "         4.01145710e-04, -6.72708640e-02, -4.23003948e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8aefa",
   "metadata": {},
   "source": [
    "Obtemos o maior autovalor da matriz de pesos de reservatório **rhoReservoir**. Dividimos a matriz por este escalar e multiplicamos pelo raio espectral desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0223c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhoReservoir = numpy.max(numpy.abs(linalg.eig(W_reservoir)[0]))\n",
    "W_reservoir *= spectral_radius / rhoReservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a50ed0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_reservoir[numpy.random.rand(N, N) < 0.9] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe50cb8",
   "metadata": {},
   "source": [
    "### (III) Matriz de estados e harvesting\n",
    "\n",
    "Criamos a matriz de estados **state_matrix** inicialmente zerada e de dimensões $(1\\ +\\ K\\ +\\ N)\\ x\\ (Janela\\ de\\ treino - Descarte)$. Cada linha da matriz armazena o bias, o input(naquele ponto) e estado de cada um dos neurônios no decorrer da janela de treino, à exceção do período do transiente que é descartado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58749d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_matrix = numpy.zeros((1 + K + N, train_length - transiente))\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c641d26",
   "metadata": {},
   "source": [
    "Passamos ao processo de harvesting, a matriz é atualizada conforme a *equação de atualização dos estados* escolhida. A variável auxiliar **state** armazena os valores de interesse e repassa para a matriz de estados.\n",
    "\n",
    "Conforme o processo é iterado nas $n$ observações da janela de treino, a matriz de estados recebe igualmente o bias (por definição é 1) e o input relativo a $n$. Valores calculados antes do ponto de corte do transiente não são adicionados na matriz de estados final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a9ada20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.50345012,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.50072158,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.0560187 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.01113151,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.05771484,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = numpy.zeros((N, 1))\n",
    "#for n in range(train_dataset.shape[0]):\n",
    "n = 0\n",
    "u = train_dataset[n,:]\n",
    "state = (1 - leaking_rate)*state + leaking_rate*numpy.tanh(numpy.dot(W_input, reshape(numpy.hstack((1, u)))) + numpy.dot(W_reservoir, state))\n",
    "#if n >= transiente:\n",
    "#    state_matrix[:, n - transiente] = numpy.hstack((1, u, state[:,0]))\n",
    "state_matrix[:, n] = numpy.hstack((1, u, state[:,0]))\n",
    "\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b495228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28100adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68,  86, 104, 122, 140, 158, 176])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = numpy.array([1, 2, 3])\n",
    "y.shape\n",
    "x = numpy.arange(10, 31).reshape((7, 3))\n",
    "x.shape\n",
    "numpy.dot(y, x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156bc4e",
   "metadata": {},
   "source": [
    "### (IV) Regressão de Ridge\n",
    "\n",
    "Aplicamos a regressão de Tikhonov para estimar a melhor matrix de pesos de saída **W_output** de dimensão $L\\ x\\ (K\\ +\\ 1\\ +\\ N)$, isso é, aquela à qual o erro com relação ao target esperado (conjunto de trainning) é o menor possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8badc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1e-8\n",
    "W_output = linalg.solve(numpy.dot(state_matrix, state_matrix.T) + reg * numpy.eye(1 + K + N), \n",
    "    numpy.dot(state_matrix, train_target.T) ).T[0]\n",
    "W_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04492f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcc05d",
   "metadata": {},
   "source": [
    "### (V) Dataset de teste\n",
    "\n",
    "Todo o processe de criação das matrizes é \"reiniciado\", perceba-se que o gerador não é inializado de novo (pode ser inicializado com outro valor), são criadas novas matrizes de pesos de entreda e de reservatório (nas mesmas condições que as anteriores, mas não identicas). \n",
    "\n",
    "O processo de harvesting é iniciado do zero, desta vez considerando apenas os dados de teste/validação, dessa forma teremos novos estados, conforme os dados apresentados e a equação de atualização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e62bea",
   "metadata": {},
   "source": [
    "### Dúvida/Constatação I\n",
    "\n",
    "Havia entendido que poderiamos gerar novas matrizes de peso (input e reservatório) e algoritmo funcionaria apenas com algum erro, mas pelo que vejo, o W_{output} tem serventia na predição somente quando as matrizes de pesos de input e reservatorio são as mesmas! (tende mudar abaixo as matrizes -> A curva tem o formato certo, mas os valores não coincidem!)\n",
    "\n",
    "Assim, **toda vez que realizarmos o trainning é necessário guardar as 3 matrizes para o teste (W_{input}, W_{reservoir} e W_{output})?**\n",
    "\n",
    "Sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_input = (numpy.random.rand(N, 1 + K) - 0.5) * input_scaling\n",
    "#W_reservoir = numpy.random.rand(N, N) - 0.5 \n",
    "#W_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rhoReservoir = numpy.max(numpy.abs(scipy.linalg.eig(W_reservoir)[0]))\n",
    "#W_reservoir *= spectral_radius / rhoReservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27de5a",
   "metadata": {},
   "source": [
    "### Truque\n",
    "\n",
    "Como não faz sentido o uso de transiente no conjunto de teste (ou ele invade o conjunto de treino ou desperdiça dados do conjunto de teste), fiz uso desse truque que vi em outra implementação de ESN, o segredo é iniciar o estado com o último estado obtido na matriz de estados do conjunto de treino!\n",
    "\n",
    "Dessa forma é necessário guardar esse vetor, mas elimina o uso de transiente e o resultado fica igualmente excelente.\n",
    "\n",
    "### OBSERVAÇÃO\n",
    "O uso dos estados transientes só faz sentido na etapa de treino pois lá tu estás usando uma função de aprendizagem e descarta o que seriam estados \"sub-ótimos\". Depois do treino realizado, tu vai entrar no modo de predição de 1, ou mais, passos adiante. Mas isso não deveria ser um truque. São duas funções **bem** distintas: uma para aprendizagem e outra para uso do modelo. A primeira depende de u, X, Win, etc. e resulta na criação/estimação de Wout, enquanto que a outra depende só de u, X, Win, W e Wout. Na segunda função, a saída é um vetor y estimado de dimensão L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = reshape(state_matrix[K + 1::,-1])\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_matrix = numpy.zeros((1 + K + N, test_length))\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ea766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(test_dataset.shape[0]):\n",
    "    u = test_dataset[n,:]\n",
    "    #state = (1 - leaking_rate)*state + leaking_rate*numpy.tanh(numpy.dot(W_input, numpy.vstack((1, u))) + numpy.dot(W_reservoir, state))\n",
    "    #state_matrix[:, n] = numpy.vstack((1, u, state))[:, 0]\n",
    "    state = (1 - leaking_rate)*state + leaking_rate*numpy.tanh(numpy.dot(W_input, reshape(numpy.hstack((1, u)))) + numpy.dot(W_reservoir, state))\n",
    "    state_matrix[:, n] = numpy.hstack((1, u, state[:,0]))\n",
    "    \n",
    "\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d87519",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2625ff8",
   "metadata": {},
   "source": [
    "### (VI) Predição\n",
    "\n",
    "Por fim, utilizamos a mesma matriz de pesos de saída **W_output** otimizada no período de trainning e aplicamo-la sobre os estados obtidos via processo de harvesting para o dataset de teste. Assim obtemos a predição dos valores $n$ steps a frente que pode ser comparado com o target (esperado) do conjunto de teste.\n",
    "\n",
    "### OBSERVAÇÃO\n",
    "\n",
    "Os comandos abaixo deveriam estar contidos na função acima, pois não entendi o porquê de fazer de forma separada, dado que o objetivo são os valores preditos (1 ou mais passos adiante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = numpy.dot(W_output, state_matrix)\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac497363",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b937ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "#ax.scatter(predict[0,:], predict[1,:], predict[2,:], color = \"blue\")\n",
    "#ax.scatter(test_target[0, :, 0], test_target[0, :, 1], test_target[0, :, 2], color = \"red\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(test_target[0, :, 0], test_target[0, :, 1], color = \"blue\", linewidth = 2, label = \"Expected\")\n",
    "plt.scatter(predict[0,:], predict[1,:], color = \"red\", linewidth = 1, label = \"Predict\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5844c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9795749",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b00489",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_target[0].T, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_target[0].T, predict, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3467b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(test_target[0].T, predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
